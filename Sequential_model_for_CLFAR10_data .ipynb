{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "467rt2Rw429J"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "# tf.config.experimental_run_functions_eagerly(True)\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.datasets.mnist as input_data\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = cifar10.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds_yr6k347fl",
        "outputId": "ef0f58e7-18eb-4cee-c54a-14623c4304a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM7YhbGG47dI",
        "outputId": "d729d983-a7d9-482b-d2d6-6bd9940c1929"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape images\n",
        "x_train[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGc4A2sP47ai",
        "outputId": "b1f1343a-4b5b-4a86-ddea-88efc9d14e90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show image\n",
        "plt.imshow(x_train[38])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "zAkGBILj47YF",
        "outputId": "ccfbcc64-544d-4045-92d0-2854484d9ccf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a0f693ac5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[38])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STGuQH_G47Vi",
        "outputId": "4e6951d3-ccf4-484b-ef9b-409f9ae379f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split\n",
        "#### train %85 data & test %15 data"
      ],
      "metadata": {
        "id": "5qGHbA8T5lFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train , y_test))\n",
        "\n",
        "X_train, X_test,y_train , y_test = train_test_split(X, y, test_size=15, random_state=42)\n"
      ],
      "metadata": {
        "id": "vUyW4eg147TE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data for predict\n",
        "y_train_for_peredct = y_train\n",
        "y_test_for_peredct = y_test\n",
        "x_train_1_perd, x_validation_perd, y_train_1_perd, y_validation_perd = train_test_split(X, y, test_size=15)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X.shape)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-A4BX3347Qk",
        "outputId": "f0e734df-a189-4599-f88d-c440c95dc27e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59985, 32, 32, 3)\n",
            "(60000, 32, 32, 3)\n",
            "[[5]\n",
            " [7]\n",
            " [5]\n",
            " ...\n",
            " [8]\n",
            " [8]\n",
            " [4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "\n",
        "print(X_test[5][1][1])\n",
        "\n",
        "y_train = to_categorical(y_train, dtype =\"uint8\")\n",
        "y_test = to_categorical(y_test, dtype =\"uint8\")\n",
        "\n",
        "y_train[1]\n",
        "\n",
        "x_train_1, x_validation, y_train_1, y_validation = train_test_split(X_train, y_train, test_size=15)\n",
        "\n",
        "x_train_1[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vW9H0pd47OO",
        "outputId": "69db343a-16a3-47db-9b63-0c85ebf162cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.41568627 0.51372549 0.03921569]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "9dvfls_e5wa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=[32, 32,3]))\n",
        "model.add(layers.Dense(200, activation='relu'))\n",
        "model.add(layers.Dense(150, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(75, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q27Lmny547JK",
        "outputId": "77242223-d7b7-41c4-c299-493fb4919dba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               614600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 150)               30150     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               15100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 75)                7575      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                760       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 668185 (2.55 MB)\n",
            "Trainable params: 668185 (2.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWcOlIOH5uBm",
        "outputId": "6202dc19-a7a9-45b1-cb1b-cfff11375b0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.layers.reshaping.flatten.Flatten at 0x7a0ff90f9f90>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a0f6728cf40>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a0f6728d1b0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a0f6728d120>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a0f6728eda0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a0f6728f250>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count_layer = 2\n",
        "weight, bias = model.layers[count_layer].get_weights()\n",
        "print(model.layers[count_layer])\n",
        "print(\"weight\", weight)\n",
        "print(\"bias\", bias)\n",
        "print(\"len bias\", len(bias))\n",
        "print(\"len weight\", len(weight))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPWbut775t_D",
        "outputId": "ffbf3560-04f3-482b-c2e8-a3421506eb39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.layers.core.dense.Dense object at 0x7a0f6728d1b0>\n",
            "weight [[-0.09834036 -0.05943937 -0.01942451 ...  0.05538246 -0.06708553\n",
            "  -0.02691187]\n",
            " [ 0.00509261 -0.05048487  0.06365238 ...  0.09966281 -0.0359401\n",
            "  -0.03314399]\n",
            " [-0.01289256 -0.01195189 -0.07371687 ...  0.03709576 -0.03053939\n",
            "  -0.0607366 ]\n",
            " ...\n",
            " [ 0.02465238 -0.05194892  0.04506204 ...  0.01928781 -0.07134028\n",
            "   0.03108774]\n",
            " [-0.01064851 -0.04768146  0.04372524 ... -0.03925287  0.03308858\n",
            "  -0.02884101]\n",
            " [ 0.04170659  0.11506304 -0.08976952 ... -0.0474991  -0.01554392\n",
            "   0.1033411 ]]\n",
            "bias [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "len bias 150\n",
            "len weight 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='sgd', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rUtymAx95t8k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define callback\n",
        "\n",
        "checkpoint_filepath = \"model_cifar10_checkpoint_save.h5\"\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, save_best_only=True)\n",
        "\n",
        "model_checkpoint_earlyEstping = keras.callbacks.EarlyStopping(monitor='loss',patience=10)\n"
      ],
      "metadata": {
        "id": "P9pz4A5W5t6E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "\n",
        "history = model.fit(x_train_1, y_train_1, batch_size=128, epochs=1000,\n",
        "                   validation_data=[x_validation, y_validation], callbacks=[model_checkpoint_callback,model_checkpoint_earlyEstping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu3WdLut5t3w",
        "outputId": "d69a1b9b-61d8-4974-e8a3-21855d370820"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "469/469 [==============================] - 10s 19ms/step - loss: 2.0653 - accuracy: 0.2559 - val_loss: 2.0377 - val_accuracy: 0.2667\n",
            "Epoch 2/1000\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.8512 - accuracy: 0.3415 - val_loss: 2.0061 - val_accuracy: 0.2667\n",
            "Epoch 3/1000\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 1.7621 - accuracy: 0.3746 - val_loss: 1.8514 - val_accuracy: 0.4000\n",
            "Epoch 4/1000\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.7014 - accuracy: 0.3980 - val_loss: 1.7341 - val_accuracy: 0.4000\n",
            "Epoch 5/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.6589 - accuracy: 0.4103 - val_loss: 1.8249 - val_accuracy: 0.4000\n",
            "Epoch 6/1000\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 1.6200 - accuracy: 0.4275 - val_loss: 1.7653 - val_accuracy: 0.2667\n",
            "Epoch 7/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.5887 - accuracy: 0.4357 - val_loss: 1.7172 - val_accuracy: 0.4000\n",
            "Epoch 8/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.5604 - accuracy: 0.4447 - val_loss: 1.6077 - val_accuracy: 0.3333\n",
            "Epoch 9/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.5347 - accuracy: 0.4552 - val_loss: 1.4832 - val_accuracy: 0.4667\n",
            "Epoch 10/1000\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.5094 - accuracy: 0.4644 - val_loss: 1.6886 - val_accuracy: 0.3333\n",
            "Epoch 11/1000\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 1.4906 - accuracy: 0.4708 - val_loss: 1.6875 - val_accuracy: 0.2667\n",
            "Epoch 12/1000\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 1.4732 - accuracy: 0.4752 - val_loss: 1.5056 - val_accuracy: 0.3333\n",
            "Epoch 13/1000\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 1.4536 - accuracy: 0.4855 - val_loss: 1.8602 - val_accuracy: 0.4667\n",
            "Epoch 14/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.4379 - accuracy: 0.4898 - val_loss: 1.4980 - val_accuracy: 0.4000\n",
            "Epoch 15/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.4243 - accuracy: 0.4939 - val_loss: 2.1444 - val_accuracy: 0.2667\n",
            "Epoch 16/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.4062 - accuracy: 0.5033 - val_loss: 1.4501 - val_accuracy: 0.2667\n",
            "Epoch 17/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.3943 - accuracy: 0.5065 - val_loss: 1.6348 - val_accuracy: 0.3333\n",
            "Epoch 18/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.3825 - accuracy: 0.5080 - val_loss: 1.6756 - val_accuracy: 0.3333\n",
            "Epoch 19/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 1.3665 - accuracy: 0.5159 - val_loss: 1.4911 - val_accuracy: 0.3333\n",
            "Epoch 20/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.3553 - accuracy: 0.5184 - val_loss: 1.9543 - val_accuracy: 0.3333\n",
            "Epoch 21/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.3429 - accuracy: 0.5232 - val_loss: 1.6040 - val_accuracy: 0.2667\n",
            "Epoch 22/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.3302 - accuracy: 0.5281 - val_loss: 1.4716 - val_accuracy: 0.3333\n",
            "Epoch 23/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 1.3229 - accuracy: 0.5308 - val_loss: 1.5656 - val_accuracy: 0.4000\n",
            "Epoch 24/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.3106 - accuracy: 0.5344 - val_loss: 1.6163 - val_accuracy: 0.4000\n",
            "Epoch 25/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.2993 - accuracy: 0.5385 - val_loss: 1.5734 - val_accuracy: 0.4000\n",
            "Epoch 26/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.2909 - accuracy: 0.5414 - val_loss: 1.4303 - val_accuracy: 0.4000\n",
            "Epoch 27/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.2809 - accuracy: 0.5449 - val_loss: 1.6629 - val_accuracy: 0.2667\n",
            "Epoch 28/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 1.2709 - accuracy: 0.5493 - val_loss: 1.4627 - val_accuracy: 0.3333\n",
            "Epoch 29/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.2621 - accuracy: 0.5511 - val_loss: 1.7174 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.2523 - accuracy: 0.5571 - val_loss: 1.5716 - val_accuracy: 0.4000\n",
            "Epoch 31/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.2430 - accuracy: 0.5598 - val_loss: 1.8645 - val_accuracy: 0.2667\n",
            "Epoch 32/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 1.2356 - accuracy: 0.5618 - val_loss: 1.5624 - val_accuracy: 0.2667\n",
            "Epoch 33/1000\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 1.2281 - accuracy: 0.5641 - val_loss: 1.4871 - val_accuracy: 0.4000\n",
            "Epoch 34/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.2188 - accuracy: 0.5674 - val_loss: 1.5276 - val_accuracy: 0.4000\n",
            "Epoch 35/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.2101 - accuracy: 0.5697 - val_loss: 1.3984 - val_accuracy: 0.4000\n",
            "Epoch 36/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.2000 - accuracy: 0.5740 - val_loss: 1.3110 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1914 - accuracy: 0.5783 - val_loss: 1.6308 - val_accuracy: 0.2667\n",
            "Epoch 38/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.1847 - accuracy: 0.5801 - val_loss: 1.5072 - val_accuracy: 0.4667\n",
            "Epoch 39/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1758 - accuracy: 0.5835 - val_loss: 1.9857 - val_accuracy: 0.3333\n",
            "Epoch 40/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.1678 - accuracy: 0.5871 - val_loss: 1.5638 - val_accuracy: 0.4000\n",
            "Epoch 41/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1633 - accuracy: 0.5871 - val_loss: 1.7436 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.1525 - accuracy: 0.5897 - val_loss: 2.0790 - val_accuracy: 0.2667\n",
            "Epoch 43/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1475 - accuracy: 0.5915 - val_loss: 1.5875 - val_accuracy: 0.3333\n",
            "Epoch 44/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.1399 - accuracy: 0.5948 - val_loss: 1.5273 - val_accuracy: 0.2667\n",
            "Epoch 45/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1322 - accuracy: 0.5974 - val_loss: 1.4005 - val_accuracy: 0.4000\n",
            "Epoch 46/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.1238 - accuracy: 0.6025 - val_loss: 1.5670 - val_accuracy: 0.3333\n",
            "Epoch 47/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.1184 - accuracy: 0.6032 - val_loss: 1.4959 - val_accuracy: 0.3333\n",
            "Epoch 48/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.1107 - accuracy: 0.6061 - val_loss: 1.4529 - val_accuracy: 0.4000\n",
            "Epoch 49/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 1.0992 - accuracy: 0.6097 - val_loss: 1.3866 - val_accuracy: 0.4000\n",
            "Epoch 50/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 1.0973 - accuracy: 0.6110 - val_loss: 1.4839 - val_accuracy: 0.3333\n",
            "Epoch 51/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0878 - accuracy: 0.6138 - val_loss: 1.7191 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0832 - accuracy: 0.6177 - val_loss: 1.6129 - val_accuracy: 0.4000\n",
            "Epoch 53/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0742 - accuracy: 0.6220 - val_loss: 1.4529 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0679 - accuracy: 0.6216 - val_loss: 1.5577 - val_accuracy: 0.3333\n",
            "Epoch 55/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0586 - accuracy: 0.6245 - val_loss: 1.5421 - val_accuracy: 0.4667\n",
            "Epoch 56/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0542 - accuracy: 0.6264 - val_loss: 1.4332 - val_accuracy: 0.4000\n",
            "Epoch 57/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0521 - accuracy: 0.6269 - val_loss: 1.3694 - val_accuracy: 0.3333\n",
            "Epoch 58/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0399 - accuracy: 0.6314 - val_loss: 1.7675 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0342 - accuracy: 0.6318 - val_loss: 2.0213 - val_accuracy: 0.3333\n",
            "Epoch 60/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0297 - accuracy: 0.6346 - val_loss: 1.5140 - val_accuracy: 0.4000\n",
            "Epoch 61/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0190 - accuracy: 0.6397 - val_loss: 1.5308 - val_accuracy: 0.5333\n",
            "Epoch 62/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0159 - accuracy: 0.6397 - val_loss: 1.7681 - val_accuracy: 0.3333\n",
            "Epoch 63/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0057 - accuracy: 0.6441 - val_loss: 1.8958 - val_accuracy: 0.3333\n",
            "Epoch 64/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 1.0016 - accuracy: 0.6457 - val_loss: 1.3520 - val_accuracy: 0.4667\n",
            "Epoch 65/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9939 - accuracy: 0.6465 - val_loss: 1.7939 - val_accuracy: 0.4000\n",
            "Epoch 66/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.9906 - accuracy: 0.6474 - val_loss: 1.3600 - val_accuracy: 0.3333\n",
            "Epoch 67/1000\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.9848 - accuracy: 0.6509 - val_loss: 1.7133 - val_accuracy: 0.4667\n",
            "Epoch 68/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.9770 - accuracy: 0.6538 - val_loss: 1.6987 - val_accuracy: 0.4000\n",
            "Epoch 69/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9702 - accuracy: 0.6551 - val_loss: 1.6340 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.9655 - accuracy: 0.6576 - val_loss: 1.4544 - val_accuracy: 0.4667\n",
            "Epoch 71/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9578 - accuracy: 0.6624 - val_loss: 1.5402 - val_accuracy: 0.4667\n",
            "Epoch 72/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.9521 - accuracy: 0.6609 - val_loss: 1.4419 - val_accuracy: 0.4000\n",
            "Epoch 73/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9476 - accuracy: 0.6633 - val_loss: 1.7251 - val_accuracy: 0.3333\n",
            "Epoch 74/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.9425 - accuracy: 0.6662 - val_loss: 1.5966 - val_accuracy: 0.5333\n",
            "Epoch 75/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9307 - accuracy: 0.6695 - val_loss: 1.4464 - val_accuracy: 0.4000\n",
            "Epoch 76/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.9299 - accuracy: 0.6700 - val_loss: 1.6023 - val_accuracy: 0.4000\n",
            "Epoch 77/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9211 - accuracy: 0.6736 - val_loss: 1.4238 - val_accuracy: 0.4667\n",
            "Epoch 78/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.9132 - accuracy: 0.6743 - val_loss: 1.4327 - val_accuracy: 0.4667\n",
            "Epoch 79/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9068 - accuracy: 0.6794 - val_loss: 1.5365 - val_accuracy: 0.4667\n",
            "Epoch 80/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.9093 - accuracy: 0.6778 - val_loss: 1.4797 - val_accuracy: 0.5333\n",
            "Epoch 81/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8985 - accuracy: 0.6832 - val_loss: 1.3044 - val_accuracy: 0.6000\n",
            "Epoch 82/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8889 - accuracy: 0.6850 - val_loss: 1.8739 - val_accuracy: 0.4000\n",
            "Epoch 83/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8907 - accuracy: 0.6852 - val_loss: 1.9098 - val_accuracy: 0.4000\n",
            "Epoch 84/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8816 - accuracy: 0.6880 - val_loss: 1.6566 - val_accuracy: 0.4000\n",
            "Epoch 85/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8789 - accuracy: 0.6877 - val_loss: 1.5624 - val_accuracy: 0.3333\n",
            "Epoch 86/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.8717 - accuracy: 0.6909 - val_loss: 1.3137 - val_accuracy: 0.3333\n",
            "Epoch 87/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8615 - accuracy: 0.6946 - val_loss: 2.0726 - val_accuracy: 0.3333\n",
            "Epoch 88/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.8565 - accuracy: 0.6966 - val_loss: 1.8994 - val_accuracy: 0.4667\n",
            "Epoch 89/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8503 - accuracy: 0.6977 - val_loss: 1.5917 - val_accuracy: 0.4667\n",
            "Epoch 90/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.8472 - accuracy: 0.6996 - val_loss: 1.8364 - val_accuracy: 0.3333\n",
            "Epoch 91/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8393 - accuracy: 0.7020 - val_loss: 1.5149 - val_accuracy: 0.3333\n",
            "Epoch 92/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.8373 - accuracy: 0.7023 - val_loss: 1.7970 - val_accuracy: 0.4000\n",
            "Epoch 93/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8314 - accuracy: 0.7041 - val_loss: 1.6360 - val_accuracy: 0.6000\n",
            "Epoch 94/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8216 - accuracy: 0.7092 - val_loss: 1.3682 - val_accuracy: 0.3333\n",
            "Epoch 95/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.8184 - accuracy: 0.7097 - val_loss: 1.3042 - val_accuracy: 0.4667\n",
            "Epoch 96/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8112 - accuracy: 0.7128 - val_loss: 1.5566 - val_accuracy: 0.4667\n",
            "Epoch 97/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8119 - accuracy: 0.7111 - val_loss: 1.4865 - val_accuracy: 0.4667\n",
            "Epoch 98/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.8066 - accuracy: 0.7118 - val_loss: 1.1437 - val_accuracy: 0.6000\n",
            "Epoch 99/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7997 - accuracy: 0.7161 - val_loss: 1.9758 - val_accuracy: 0.3333\n",
            "Epoch 100/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7895 - accuracy: 0.7188 - val_loss: 1.5090 - val_accuracy: 0.6000\n",
            "Epoch 101/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7902 - accuracy: 0.7197 - val_loss: 1.5765 - val_accuracy: 0.5333\n",
            "Epoch 102/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7822 - accuracy: 0.7228 - val_loss: 1.5763 - val_accuracy: 0.5333\n",
            "Epoch 103/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7816 - accuracy: 0.7204 - val_loss: 1.6985 - val_accuracy: 0.4000\n",
            "Epoch 104/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7700 - accuracy: 0.7264 - val_loss: 1.4048 - val_accuracy: 0.4667\n",
            "Epoch 105/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7704 - accuracy: 0.7269 - val_loss: 1.8388 - val_accuracy: 0.3333\n",
            "Epoch 106/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.7626 - accuracy: 0.7298 - val_loss: 1.3236 - val_accuracy: 0.4667\n",
            "Epoch 107/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7556 - accuracy: 0.7313 - val_loss: 1.4804 - val_accuracy: 0.5333\n",
            "Epoch 108/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7510 - accuracy: 0.7356 - val_loss: 1.6733 - val_accuracy: 0.4667\n",
            "Epoch 109/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7422 - accuracy: 0.7376 - val_loss: 1.7745 - val_accuracy: 0.4667\n",
            "Epoch 110/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7445 - accuracy: 0.7356 - val_loss: 1.4730 - val_accuracy: 0.3333\n",
            "Epoch 111/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7323 - accuracy: 0.7404 - val_loss: 1.1493 - val_accuracy: 0.5333\n",
            "Epoch 112/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7326 - accuracy: 0.7385 - val_loss: 1.6976 - val_accuracy: 0.4000\n",
            "Epoch 113/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7233 - accuracy: 0.7438 - val_loss: 1.7479 - val_accuracy: 0.4667\n",
            "Epoch 114/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7204 - accuracy: 0.7429 - val_loss: 1.7012 - val_accuracy: 0.4667\n",
            "Epoch 115/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7136 - accuracy: 0.7458 - val_loss: 1.4359 - val_accuracy: 0.6000\n",
            "Epoch 116/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7101 - accuracy: 0.7469 - val_loss: 1.2146 - val_accuracy: 0.6667\n",
            "Epoch 117/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.7064 - accuracy: 0.7505 - val_loss: 1.9077 - val_accuracy: 0.2667\n",
            "Epoch 118/1000\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.6995 - accuracy: 0.7514 - val_loss: 1.4073 - val_accuracy: 0.4667\n",
            "Epoch 119/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6894 - accuracy: 0.7551 - val_loss: 1.2732 - val_accuracy: 0.4667\n",
            "Epoch 120/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6965 - accuracy: 0.7535 - val_loss: 1.2058 - val_accuracy: 0.7333\n",
            "Epoch 121/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6839 - accuracy: 0.7583 - val_loss: 1.4113 - val_accuracy: 0.5333\n",
            "Epoch 122/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6793 - accuracy: 0.7587 - val_loss: 1.9080 - val_accuracy: 0.4667\n",
            "Epoch 123/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6757 - accuracy: 0.7615 - val_loss: 1.7087 - val_accuracy: 0.5333\n",
            "Epoch 124/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6643 - accuracy: 0.7634 - val_loss: 1.2566 - val_accuracy: 0.4667\n",
            "Epoch 125/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.6648 - accuracy: 0.7625 - val_loss: 1.4171 - val_accuracy: 0.5333\n",
            "Epoch 126/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6572 - accuracy: 0.7672 - val_loss: 1.7505 - val_accuracy: 0.4000\n",
            "Epoch 127/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6531 - accuracy: 0.7693 - val_loss: 1.4527 - val_accuracy: 0.5333\n",
            "Epoch 128/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6547 - accuracy: 0.7668 - val_loss: 2.1032 - val_accuracy: 0.3333\n",
            "Epoch 129/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6455 - accuracy: 0.7705 - val_loss: 1.9693 - val_accuracy: 0.3333\n",
            "Epoch 130/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6407 - accuracy: 0.7724 - val_loss: 1.4750 - val_accuracy: 0.4000\n",
            "Epoch 131/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6372 - accuracy: 0.7730 - val_loss: 1.5610 - val_accuracy: 0.4667\n",
            "Epoch 132/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6364 - accuracy: 0.7730 - val_loss: 1.5722 - val_accuracy: 0.5333\n",
            "Epoch 133/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6343 - accuracy: 0.7749 - val_loss: 2.2803 - val_accuracy: 0.4667\n",
            "Epoch 134/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6162 - accuracy: 0.7801 - val_loss: 1.1230 - val_accuracy: 0.6000\n",
            "Epoch 135/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6174 - accuracy: 0.7807 - val_loss: 1.9368 - val_accuracy: 0.4000\n",
            "Epoch 136/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.6243 - accuracy: 0.7778 - val_loss: 1.4635 - val_accuracy: 0.5333\n",
            "Epoch 137/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.6103 - accuracy: 0.7819 - val_loss: 2.2100 - val_accuracy: 0.4000\n",
            "Epoch 138/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.6052 - accuracy: 0.7839 - val_loss: 1.5108 - val_accuracy: 0.4667\n",
            "Epoch 139/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5985 - accuracy: 0.7878 - val_loss: 1.7772 - val_accuracy: 0.4000\n",
            "Epoch 140/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.6033 - accuracy: 0.7864 - val_loss: 1.6259 - val_accuracy: 0.5333\n",
            "Epoch 141/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.5967 - accuracy: 0.7893 - val_loss: 1.1195 - val_accuracy: 0.4667\n",
            "Epoch 142/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.5870 - accuracy: 0.7914 - val_loss: 1.2575 - val_accuracy: 0.6000\n",
            "Epoch 143/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.5804 - accuracy: 0.7937 - val_loss: 1.2425 - val_accuracy: 0.5333\n",
            "Epoch 144/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5778 - accuracy: 0.7944 - val_loss: 1.5705 - val_accuracy: 0.4667\n",
            "Epoch 145/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.5769 - accuracy: 0.7954 - val_loss: 1.6268 - val_accuracy: 0.4000\n",
            "Epoch 146/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5730 - accuracy: 0.7967 - val_loss: 1.7633 - val_accuracy: 0.4667\n",
            "Epoch 147/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5646 - accuracy: 0.7994 - val_loss: 1.5182 - val_accuracy: 0.4000\n",
            "Epoch 148/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5629 - accuracy: 0.8016 - val_loss: 2.0210 - val_accuracy: 0.4000\n",
            "Epoch 149/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5531 - accuracy: 0.8039 - val_loss: 1.7356 - val_accuracy: 0.5333\n",
            "Epoch 150/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5618 - accuracy: 0.8007 - val_loss: 2.6555 - val_accuracy: 0.4000\n",
            "Epoch 151/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5538 - accuracy: 0.8017 - val_loss: 1.9533 - val_accuracy: 0.5333\n",
            "Epoch 152/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5527 - accuracy: 0.8040 - val_loss: 1.4394 - val_accuracy: 0.5333\n",
            "Epoch 153/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5413 - accuracy: 0.8082 - val_loss: 1.3934 - val_accuracy: 0.6000\n",
            "Epoch 154/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5470 - accuracy: 0.8075 - val_loss: 1.9943 - val_accuracy: 0.6000\n",
            "Epoch 155/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5421 - accuracy: 0.8099 - val_loss: 1.8863 - val_accuracy: 0.4667\n",
            "Epoch 156/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5289 - accuracy: 0.8111 - val_loss: 1.5646 - val_accuracy: 0.5333\n",
            "Epoch 157/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5246 - accuracy: 0.8131 - val_loss: 2.4936 - val_accuracy: 0.4667\n",
            "Epoch 158/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5172 - accuracy: 0.8157 - val_loss: 2.1821 - val_accuracy: 0.4667\n",
            "Epoch 159/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5232 - accuracy: 0.8149 - val_loss: 1.4553 - val_accuracy: 0.5333\n",
            "Epoch 160/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5169 - accuracy: 0.8169 - val_loss: 1.4219 - val_accuracy: 0.4667\n",
            "Epoch 161/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5057 - accuracy: 0.8196 - val_loss: 2.4302 - val_accuracy: 0.3333\n",
            "Epoch 162/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.5015 - accuracy: 0.8221 - val_loss: 2.4858 - val_accuracy: 0.4000\n",
            "Epoch 163/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.5211 - accuracy: 0.8157 - val_loss: 1.7966 - val_accuracy: 0.5333\n",
            "Epoch 164/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4908 - accuracy: 0.8264 - val_loss: 1.7099 - val_accuracy: 0.5333\n",
            "Epoch 165/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4870 - accuracy: 0.8271 - val_loss: 2.2419 - val_accuracy: 0.4667\n",
            "Epoch 166/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4922 - accuracy: 0.8270 - val_loss: 1.4072 - val_accuracy: 0.6000\n",
            "Epoch 167/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4823 - accuracy: 0.8290 - val_loss: 1.2904 - val_accuracy: 0.5333\n",
            "Epoch 168/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4799 - accuracy: 0.8313 - val_loss: 1.8941 - val_accuracy: 0.4000\n",
            "Epoch 169/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4725 - accuracy: 0.8320 - val_loss: 1.9666 - val_accuracy: 0.5333\n",
            "Epoch 170/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.4915 - accuracy: 0.8261 - val_loss: 1.7752 - val_accuracy: 0.6000\n",
            "Epoch 171/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4763 - accuracy: 0.8298 - val_loss: 1.6499 - val_accuracy: 0.6000\n",
            "Epoch 172/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4651 - accuracy: 0.8363 - val_loss: 1.8703 - val_accuracy: 0.5333\n",
            "Epoch 173/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4666 - accuracy: 0.8351 - val_loss: 1.3388 - val_accuracy: 0.6667\n",
            "Epoch 174/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4600 - accuracy: 0.8379 - val_loss: 1.4435 - val_accuracy: 0.4667\n",
            "Epoch 175/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4599 - accuracy: 0.8378 - val_loss: 1.9313 - val_accuracy: 0.5333\n",
            "Epoch 176/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4549 - accuracy: 0.8393 - val_loss: 1.9073 - val_accuracy: 0.4000\n",
            "Epoch 177/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4398 - accuracy: 0.8448 - val_loss: 1.4139 - val_accuracy: 0.5333\n",
            "Epoch 178/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4433 - accuracy: 0.8418 - val_loss: 1.9396 - val_accuracy: 0.6000\n",
            "Epoch 179/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4503 - accuracy: 0.8393 - val_loss: 2.4966 - val_accuracy: 0.3333\n",
            "Epoch 180/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4339 - accuracy: 0.8465 - val_loss: 1.8380 - val_accuracy: 0.5333\n",
            "Epoch 181/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4363 - accuracy: 0.8445 - val_loss: 1.7009 - val_accuracy: 0.4667\n",
            "Epoch 182/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4293 - accuracy: 0.8484 - val_loss: 1.7859 - val_accuracy: 0.5333\n",
            "Epoch 183/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4474 - accuracy: 0.8432 - val_loss: 1.6151 - val_accuracy: 0.5333\n",
            "Epoch 184/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4138 - accuracy: 0.8534 - val_loss: 2.3308 - val_accuracy: 0.4000\n",
            "Epoch 185/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.4051 - accuracy: 0.8574 - val_loss: 2.3139 - val_accuracy: 0.4667\n",
            "Epoch 186/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4186 - accuracy: 0.8541 - val_loss: 2.0506 - val_accuracy: 0.4667\n",
            "Epoch 187/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.4339 - accuracy: 0.8463 - val_loss: 2.1742 - val_accuracy: 0.4667\n",
            "Epoch 188/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3954 - accuracy: 0.8623 - val_loss: 1.7651 - val_accuracy: 0.4667\n",
            "Epoch 189/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4142 - accuracy: 0.8557 - val_loss: 2.2676 - val_accuracy: 0.5333\n",
            "Epoch 190/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3966 - accuracy: 0.8580 - val_loss: 1.6496 - val_accuracy: 0.4667\n",
            "Epoch 191/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4019 - accuracy: 0.8583 - val_loss: 1.8898 - val_accuracy: 0.4667\n",
            "Epoch 192/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3960 - accuracy: 0.8599 - val_loss: 0.8428 - val_accuracy: 0.7333\n",
            "Epoch 193/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4095 - accuracy: 0.8568 - val_loss: 1.9394 - val_accuracy: 0.4667\n",
            "Epoch 194/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3904 - accuracy: 0.8622 - val_loss: 2.0430 - val_accuracy: 0.4667\n",
            "Epoch 195/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3983 - accuracy: 0.8588 - val_loss: 2.0567 - val_accuracy: 0.4667\n",
            "Epoch 196/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3913 - accuracy: 0.8618 - val_loss: 2.2792 - val_accuracy: 0.5333\n",
            "Epoch 197/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3789 - accuracy: 0.8675 - val_loss: 1.2801 - val_accuracy: 0.6667\n",
            "Epoch 198/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3703 - accuracy: 0.8696 - val_loss: 1.3433 - val_accuracy: 0.6000\n",
            "Epoch 199/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3678 - accuracy: 0.8685 - val_loss: 1.8003 - val_accuracy: 0.6000\n",
            "Epoch 200/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3710 - accuracy: 0.8704 - val_loss: 1.8580 - val_accuracy: 0.6000\n",
            "Epoch 201/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3764 - accuracy: 0.8680 - val_loss: 3.0435 - val_accuracy: 0.4667\n",
            "Epoch 202/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3632 - accuracy: 0.8722 - val_loss: 3.2135 - val_accuracy: 0.3333\n",
            "Epoch 203/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3984 - accuracy: 0.8617 - val_loss: 2.1789 - val_accuracy: 0.4667\n",
            "Epoch 204/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3733 - accuracy: 0.8695 - val_loss: 1.4618 - val_accuracy: 0.5333\n",
            "Epoch 205/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3715 - accuracy: 0.8720 - val_loss: 3.0548 - val_accuracy: 0.4000\n",
            "Epoch 206/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3542 - accuracy: 0.8761 - val_loss: 1.9601 - val_accuracy: 0.6000\n",
            "Epoch 207/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3444 - accuracy: 0.8806 - val_loss: 2.5252 - val_accuracy: 0.4667\n",
            "Epoch 208/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.3421 - accuracy: 0.8792 - val_loss: 1.6789 - val_accuracy: 0.4667\n",
            "Epoch 209/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.3330 - accuracy: 0.8829 - val_loss: 2.6574 - val_accuracy: 0.4000\n",
            "Epoch 210/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3523 - accuracy: 0.8773 - val_loss: 2.1894 - val_accuracy: 0.6000\n",
            "Epoch 211/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.3477 - accuracy: 0.8775 - val_loss: 1.6312 - val_accuracy: 0.7333\n",
            "Epoch 212/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3318 - accuracy: 0.8849 - val_loss: 2.6490 - val_accuracy: 0.4667\n",
            "Epoch 213/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3418 - accuracy: 0.8806 - val_loss: 1.9867 - val_accuracy: 0.5333\n",
            "Epoch 214/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3346 - accuracy: 0.8844 - val_loss: 1.9350 - val_accuracy: 0.6000\n",
            "Epoch 215/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3257 - accuracy: 0.8846 - val_loss: 1.9754 - val_accuracy: 0.5333\n",
            "Epoch 216/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3341 - accuracy: 0.8832 - val_loss: 1.7040 - val_accuracy: 0.7333\n",
            "Epoch 217/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3299 - accuracy: 0.8862 - val_loss: 2.4242 - val_accuracy: 0.4667\n",
            "Epoch 218/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3302 - accuracy: 0.8861 - val_loss: 2.0744 - val_accuracy: 0.5333\n",
            "Epoch 219/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2981 - accuracy: 0.8983 - val_loss: 2.3339 - val_accuracy: 0.6000\n",
            "Epoch 220/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3256 - accuracy: 0.8848 - val_loss: 2.6109 - val_accuracy: 0.4667\n",
            "Epoch 221/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3098 - accuracy: 0.8919 - val_loss: 2.5761 - val_accuracy: 0.4667\n",
            "Epoch 222/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3077 - accuracy: 0.8941 - val_loss: 2.0516 - val_accuracy: 0.5333\n",
            "Epoch 223/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2812 - accuracy: 0.9028 - val_loss: 1.5831 - val_accuracy: 0.8000\n",
            "Epoch 224/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.3445 - accuracy: 0.8837 - val_loss: 2.0292 - val_accuracy: 0.5333\n",
            "Epoch 225/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3116 - accuracy: 0.8916 - val_loss: 3.2718 - val_accuracy: 0.5333\n",
            "Epoch 226/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2927 - accuracy: 0.8998 - val_loss: 1.7495 - val_accuracy: 0.6667\n",
            "Epoch 227/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2930 - accuracy: 0.8977 - val_loss: 2.6291 - val_accuracy: 0.4667\n",
            "Epoch 228/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2909 - accuracy: 0.8977 - val_loss: 2.9009 - val_accuracy: 0.4667\n",
            "Epoch 229/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2705 - accuracy: 0.9057 - val_loss: 2.3351 - val_accuracy: 0.4667\n",
            "Epoch 230/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.3346 - accuracy: 0.8860 - val_loss: 1.6675 - val_accuracy: 0.5333\n",
            "Epoch 231/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.2738 - accuracy: 0.9045 - val_loss: 2.6166 - val_accuracy: 0.5333\n",
            "Epoch 232/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2838 - accuracy: 0.9031 - val_loss: 1.9456 - val_accuracy: 0.6000\n",
            "Epoch 233/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2922 - accuracy: 0.9003 - val_loss: 2.1541 - val_accuracy: 0.5333\n",
            "Epoch 234/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2883 - accuracy: 0.8982 - val_loss: 2.0171 - val_accuracy: 0.4667\n",
            "Epoch 235/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2862 - accuracy: 0.9021 - val_loss: 1.9806 - val_accuracy: 0.6667\n",
            "Epoch 236/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2831 - accuracy: 0.9060 - val_loss: 2.1712 - val_accuracy: 0.6667\n",
            "Epoch 237/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2532 - accuracy: 0.9130 - val_loss: 2.6828 - val_accuracy: 0.5333\n",
            "Epoch 238/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2702 - accuracy: 0.9049 - val_loss: 2.5371 - val_accuracy: 0.6667\n",
            "Epoch 239/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2848 - accuracy: 0.9048 - val_loss: 1.5584 - val_accuracy: 0.6000\n",
            "Epoch 240/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2551 - accuracy: 0.9118 - val_loss: 1.7105 - val_accuracy: 0.6000\n",
            "Epoch 241/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2789 - accuracy: 0.9039 - val_loss: 2.1791 - val_accuracy: 0.5333\n",
            "Epoch 242/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2581 - accuracy: 0.9114 - val_loss: 2.0846 - val_accuracy: 0.6667\n",
            "Epoch 243/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2379 - accuracy: 0.9184 - val_loss: 2.6891 - val_accuracy: 0.5333\n",
            "Epoch 244/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2576 - accuracy: 0.9119 - val_loss: 2.5777 - val_accuracy: 0.5333\n",
            "Epoch 245/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2313 - accuracy: 0.9223 - val_loss: 2.0774 - val_accuracy: 0.6667\n",
            "Epoch 246/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2656 - accuracy: 0.9106 - val_loss: 3.4018 - val_accuracy: 0.4667\n",
            "Epoch 247/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2467 - accuracy: 0.9176 - val_loss: 2.0349 - val_accuracy: 0.6667\n",
            "Epoch 248/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2666 - accuracy: 0.9084 - val_loss: 2.1193 - val_accuracy: 0.6667\n",
            "Epoch 249/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2582 - accuracy: 0.9132 - val_loss: 2.7748 - val_accuracy: 0.4667\n",
            "Epoch 250/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2283 - accuracy: 0.9223 - val_loss: 2.2012 - val_accuracy: 0.6000\n",
            "Epoch 251/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2586 - accuracy: 0.9118 - val_loss: 3.0815 - val_accuracy: 0.5333\n",
            "Epoch 252/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.2083 - accuracy: 0.9299 - val_loss: 2.6251 - val_accuracy: 0.6667\n",
            "Epoch 253/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.2318 - accuracy: 0.9208 - val_loss: 2.4974 - val_accuracy: 0.5333\n",
            "Epoch 254/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2820 - accuracy: 0.9064 - val_loss: 2.7839 - val_accuracy: 0.4667\n",
            "Epoch 255/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2764 - accuracy: 0.9086 - val_loss: 2.5013 - val_accuracy: 0.4667\n",
            "Epoch 256/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2290 - accuracy: 0.9220 - val_loss: 2.3177 - val_accuracy: 0.6000\n",
            "Epoch 257/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2571 - accuracy: 0.9164 - val_loss: 3.5129 - val_accuracy: 0.5333\n",
            "Epoch 258/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1933 - accuracy: 0.9344 - val_loss: 3.0568 - val_accuracy: 0.5333\n",
            "Epoch 259/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2182 - accuracy: 0.9296 - val_loss: 2.0149 - val_accuracy: 0.6000\n",
            "Epoch 260/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2261 - accuracy: 0.9265 - val_loss: 2.6513 - val_accuracy: 0.5333\n",
            "Epoch 261/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1890 - accuracy: 0.9351 - val_loss: 2.3933 - val_accuracy: 0.4667\n",
            "Epoch 262/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1859 - accuracy: 0.9371 - val_loss: 2.8892 - val_accuracy: 0.6667\n",
            "Epoch 263/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2471 - accuracy: 0.9229 - val_loss: 2.1243 - val_accuracy: 0.7333\n",
            "Epoch 264/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2494 - accuracy: 0.9195 - val_loss: 3.1606 - val_accuracy: 0.5333\n",
            "Epoch 265/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.2162 - accuracy: 0.9292 - val_loss: 2.3788 - val_accuracy: 0.4667\n",
            "Epoch 266/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2485 - accuracy: 0.9225 - val_loss: 2.5652 - val_accuracy: 0.6000\n",
            "Epoch 267/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1879 - accuracy: 0.9367 - val_loss: 2.3350 - val_accuracy: 0.6000\n",
            "Epoch 268/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2193 - accuracy: 0.9299 - val_loss: 2.7803 - val_accuracy: 0.6000\n",
            "Epoch 269/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2004 - accuracy: 0.9370 - val_loss: 2.8295 - val_accuracy: 0.5333\n",
            "Epoch 270/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.2586 - accuracy: 0.9193 - val_loss: 1.7280 - val_accuracy: 0.6000\n",
            "Epoch 271/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1818 - accuracy: 0.9394 - val_loss: 2.4885 - val_accuracy: 0.6000\n",
            "Epoch 272/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.1831 - accuracy: 0.9428 - val_loss: 2.4416 - val_accuracy: 0.6000\n",
            "Epoch 273/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1796 - accuracy: 0.9406 - val_loss: 2.1674 - val_accuracy: 0.6667\n",
            "Epoch 274/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1835 - accuracy: 0.9389 - val_loss: 2.7259 - val_accuracy: 0.6667\n",
            "Epoch 275/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2502 - accuracy: 0.9227 - val_loss: 1.8710 - val_accuracy: 0.6667\n",
            "Epoch 276/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.1580 - accuracy: 0.9481 - val_loss: 3.3525 - val_accuracy: 0.5333\n",
            "Epoch 277/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2251 - accuracy: 0.9309 - val_loss: 2.1952 - val_accuracy: 0.6667\n",
            "Epoch 278/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1596 - accuracy: 0.9475 - val_loss: 2.1637 - val_accuracy: 0.7333\n",
            "Epoch 279/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2087 - accuracy: 0.9330 - val_loss: 2.4908 - val_accuracy: 0.5333\n",
            "Epoch 280/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1587 - accuracy: 0.9479 - val_loss: 2.4017 - val_accuracy: 0.7333\n",
            "Epoch 281/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2290 - accuracy: 0.9310 - val_loss: 3.9696 - val_accuracy: 0.4667\n",
            "Epoch 282/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2384 - accuracy: 0.9262 - val_loss: 2.8874 - val_accuracy: 0.5333\n",
            "Epoch 283/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1759 - accuracy: 0.9439 - val_loss: 3.0874 - val_accuracy: 0.5333\n",
            "Epoch 284/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1721 - accuracy: 0.9484 - val_loss: 2.8799 - val_accuracy: 0.4667\n",
            "Epoch 285/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1668 - accuracy: 0.9464 - val_loss: 3.7199 - val_accuracy: 0.6000\n",
            "Epoch 286/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1536 - accuracy: 0.9491 - val_loss: 2.7024 - val_accuracy: 0.5333\n",
            "Epoch 287/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.1994 - accuracy: 0.9389 - val_loss: 2.7700 - val_accuracy: 0.6000\n",
            "Epoch 288/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1201 - accuracy: 0.9632 - val_loss: 2.3005 - val_accuracy: 0.6000\n",
            "Epoch 289/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1745 - accuracy: 0.9458 - val_loss: 2.5806 - val_accuracy: 0.6667\n",
            "Epoch 290/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1242 - accuracy: 0.9605 - val_loss: 2.3136 - val_accuracy: 0.4667\n",
            "Epoch 291/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2655 - accuracy: 0.9178 - val_loss: 2.3280 - val_accuracy: 0.6667\n",
            "Epoch 292/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1476 - accuracy: 0.9536 - val_loss: 2.0039 - val_accuracy: 0.6000\n",
            "Epoch 293/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 2.7432 - val_accuracy: 0.4000\n",
            "Epoch 294/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1830 - accuracy: 0.9398 - val_loss: 2.4628 - val_accuracy: 0.5333\n",
            "Epoch 295/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1483 - accuracy: 0.9544 - val_loss: 3.0197 - val_accuracy: 0.5333\n",
            "Epoch 296/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1736 - accuracy: 0.9471 - val_loss: 3.3866 - val_accuracy: 0.5333\n",
            "Epoch 297/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2131 - accuracy: 0.9323 - val_loss: 2.4537 - val_accuracy: 0.6000\n",
            "Epoch 298/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1025 - accuracy: 0.9690 - val_loss: 2.8458 - val_accuracy: 0.4667\n",
            "Epoch 299/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1733 - accuracy: 0.9496 - val_loss: 2.9476 - val_accuracy: 0.5333\n",
            "Epoch 300/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2704 - accuracy: 0.9248 - val_loss: 3.3225 - val_accuracy: 0.5333\n",
            "Epoch 301/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 2.5566 - val_accuracy: 0.6667\n",
            "Epoch 302/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0887 - accuracy: 0.9742 - val_loss: 2.7257 - val_accuracy: 0.6000\n",
            "Epoch 303/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0886 - accuracy: 0.9745 - val_loss: 2.6052 - val_accuracy: 0.6000\n",
            "Epoch 304/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2050 - accuracy: 0.9412 - val_loss: 2.7165 - val_accuracy: 0.5333\n",
            "Epoch 305/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2081 - accuracy: 0.9387 - val_loss: 3.0857 - val_accuracy: 0.5333\n",
            "Epoch 306/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.1031 - accuracy: 0.9686 - val_loss: 3.4348 - val_accuracy: 0.5333\n",
            "Epoch 307/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0825 - accuracy: 0.9763 - val_loss: 3.3983 - val_accuracy: 0.6667\n",
            "Epoch 308/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2459 - accuracy: 0.9261 - val_loss: 2.6996 - val_accuracy: 0.6000\n",
            "Epoch 309/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0915 - accuracy: 0.9733 - val_loss: 2.2767 - val_accuracy: 0.6667\n",
            "Epoch 310/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2222 - accuracy: 0.9386 - val_loss: 5.8143 - val_accuracy: 0.3333\n",
            "Epoch 311/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1532 - accuracy: 0.9562 - val_loss: 2.6344 - val_accuracy: 0.4667\n",
            "Epoch 312/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0864 - accuracy: 0.9745 - val_loss: 2.9799 - val_accuracy: 0.5333\n",
            "Epoch 313/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0666 - accuracy: 0.9825 - val_loss: 2.9979 - val_accuracy: 0.6000\n",
            "Epoch 314/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0716 - accuracy: 0.9802 - val_loss: 4.3812 - val_accuracy: 0.4667\n",
            "Epoch 315/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.4276 - accuracy: 0.8726 - val_loss: 2.7243 - val_accuracy: 0.4667\n",
            "Epoch 316/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0963 - accuracy: 0.9712 - val_loss: 2.5642 - val_accuracy: 0.6667\n",
            "Epoch 317/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0679 - accuracy: 0.9829 - val_loss: 2.7584 - val_accuracy: 0.7333\n",
            "Epoch 318/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0666 - accuracy: 0.9827 - val_loss: 2.5253 - val_accuracy: 0.6000\n",
            "Epoch 319/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0639 - accuracy: 0.9833 - val_loss: 2.9323 - val_accuracy: 0.6000\n",
            "Epoch 320/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2087 - accuracy: 0.9440 - val_loss: 3.2558 - val_accuracy: 0.5333\n",
            "Epoch 321/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 3.0085 - val_accuracy: 0.5333\n",
            "Epoch 322/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0965 - accuracy: 0.9714 - val_loss: 2.5364 - val_accuracy: 0.6000\n",
            "Epoch 323/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0598 - accuracy: 0.9846 - val_loss: 2.7346 - val_accuracy: 0.6000\n",
            "Epoch 324/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0617 - accuracy: 0.9834 - val_loss: 2.7164 - val_accuracy: 0.6000\n",
            "Epoch 325/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0606 - accuracy: 0.9835 - val_loss: 3.1243 - val_accuracy: 0.6000\n",
            "Epoch 326/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0491 - accuracy: 0.9884 - val_loss: 3.1301 - val_accuracy: 0.6000\n",
            "Epoch 327/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.4745 - accuracy: 0.8711 - val_loss: 3.2599 - val_accuracy: 0.5333\n",
            "Epoch 328/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1399 - accuracy: 0.9545 - val_loss: 3.3345 - val_accuracy: 0.6000\n",
            "Epoch 329/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0730 - accuracy: 0.9794 - val_loss: 2.8444 - val_accuracy: 0.6667\n",
            "Epoch 330/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0557 - accuracy: 0.9865 - val_loss: 2.7596 - val_accuracy: 0.6667\n",
            "Epoch 331/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0484 - accuracy: 0.9887 - val_loss: 2.5193 - val_accuracy: 0.6667\n",
            "Epoch 332/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0468 - accuracy: 0.9891 - val_loss: 2.6465 - val_accuracy: 0.6000\n",
            "Epoch 333/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1817 - accuracy: 0.9486 - val_loss: 2.4145 - val_accuracy: 0.6000\n",
            "Epoch 334/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 2.6024 - val_accuracy: 0.6667\n",
            "Epoch 335/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0463 - accuracy: 0.9886 - val_loss: 3.0229 - val_accuracy: 0.6000\n",
            "Epoch 336/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0388 - accuracy: 0.9919 - val_loss: 2.9088 - val_accuracy: 0.6000\n",
            "Epoch 337/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0411 - accuracy: 0.9908 - val_loss: 3.4717 - val_accuracy: 0.5333\n",
            "Epoch 338/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.2574 - accuracy: 0.9335 - val_loss: 3.0812 - val_accuracy: 0.5333\n",
            "Epoch 339/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.3284 - accuracy: 0.9003 - val_loss: 2.1982 - val_accuracy: 0.6667\n",
            "Epoch 340/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1642 - accuracy: 0.9513 - val_loss: 3.2192 - val_accuracy: 0.6000\n",
            "Epoch 341/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0498 - accuracy: 0.9882 - val_loss: 2.8099 - val_accuracy: 0.6667\n",
            "Epoch 342/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 2.7022 - val_accuracy: 0.6000\n",
            "Epoch 343/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0409 - accuracy: 0.9908 - val_loss: 2.6563 - val_accuracy: 0.6667\n",
            "Epoch 344/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0376 - accuracy: 0.9923 - val_loss: 3.6744 - val_accuracy: 0.5333\n",
            "Epoch 345/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0363 - accuracy: 0.9926 - val_loss: 2.8515 - val_accuracy: 0.6000\n",
            "Epoch 346/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0341 - accuracy: 0.9931 - val_loss: 3.0825 - val_accuracy: 0.6667\n",
            "Epoch 347/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0331 - accuracy: 0.9933 - val_loss: 3.1096 - val_accuracy: 0.6667\n",
            "Epoch 348/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0349 - accuracy: 0.9924 - val_loss: 3.7369 - val_accuracy: 0.5333\n",
            "Epoch 349/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1018 - accuracy: 0.9804 - val_loss: 4.5779 - val_accuracy: 0.6000\n",
            "Epoch 350/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.4850 - accuracy: 0.8556 - val_loss: 2.3152 - val_accuracy: 0.4667\n",
            "Epoch 351/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.2055 - accuracy: 0.9322 - val_loss: 2.6787 - val_accuracy: 0.6000\n",
            "Epoch 352/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 2.6325 - val_accuracy: 0.5333\n",
            "Epoch 353/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0371 - accuracy: 0.9925 - val_loss: 3.0392 - val_accuracy: 0.6000\n",
            "Epoch 354/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0329 - accuracy: 0.9939 - val_loss: 2.7720 - val_accuracy: 0.6000\n",
            "Epoch 355/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0335 - accuracy: 0.9931 - val_loss: 2.6515 - val_accuracy: 0.6000\n",
            "Epoch 356/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0303 - accuracy: 0.9941 - val_loss: 2.9722 - val_accuracy: 0.6000\n",
            "Epoch 357/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0275 - accuracy: 0.9949 - val_loss: 2.8634 - val_accuracy: 0.6667\n",
            "Epoch 358/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 3.2688 - val_accuracy: 0.6000\n",
            "Epoch 359/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0260 - accuracy: 0.9957 - val_loss: 3.1165 - val_accuracy: 0.7333\n",
            "Epoch 360/1000\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 2.9867 - val_accuracy: 0.6000\n",
            "Epoch 361/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0245 - accuracy: 0.9957 - val_loss: 3.0364 - val_accuracy: 0.6000\n",
            "Epoch 362/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0227 - accuracy: 0.9962 - val_loss: 3.1361 - val_accuracy: 0.6667\n",
            "Epoch 363/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0228 - accuracy: 0.9961 - val_loss: 2.9323 - val_accuracy: 0.5333\n",
            "Epoch 364/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 3.1431 - val_accuracy: 0.7333\n",
            "Epoch 365/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 3.4498 - val_accuracy: 0.6667\n",
            "Epoch 366/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0200 - accuracy: 0.9968 - val_loss: 3.1169 - val_accuracy: 0.6000\n",
            "Epoch 367/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0194 - accuracy: 0.9972 - val_loss: 3.0207 - val_accuracy: 0.7333\n",
            "Epoch 368/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.7519 - accuracy: 0.8050 - val_loss: 1.6639 - val_accuracy: 0.6000\n",
            "Epoch 369/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.3873 - accuracy: 0.8745 - val_loss: 2.8856 - val_accuracy: 0.6667\n",
            "Epoch 370/1000\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 0.2672 - accuracy: 0.9117 - val_loss: 4.7850 - val_accuracy: 0.4667\n",
            "Epoch 371/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.1099 - accuracy: 0.9677 - val_loss: 3.0849 - val_accuracy: 0.6000\n",
            "Epoch 372/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0450 - accuracy: 0.9907 - val_loss: 2.0714 - val_accuracy: 0.6667\n",
            "Epoch 373/1000\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0338 - accuracy: 0.9940 - val_loss: 3.2521 - val_accuracy: 0.6667\n",
            "Epoch 374/1000\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0308 - accuracy: 0.9939 - val_loss: 3.5118 - val_accuracy: 0.6000\n",
            "Epoch 375/1000\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0282 - accuracy: 0.9950 - val_loss: 3.4884 - val_accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hat_probs = model.predict(x_train_1, verbose=0)\n",
        "y_train_hat_classes = np.argmax(y_train_hat_probs, axis=1)\n"
      ],
      "metadata": {
        "id": "9qdVtij15t1I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hat_probs = model.predict(X_test, verbose=0)\n",
        "y_test_hat_classes = np.argmax(y_test_hat_probs,axis=1)\n"
      ],
      "metadata": {
        "id": "tcvg-KIv6Vbe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_validation_hat_probs = model.predict(x_validation, verbose=0)\n",
        "y_validation_hat_classes = np.argmax(y_validation_hat_probs, axis=1)\n"
      ],
      "metadata": {
        "id": "-S2WeTz26VY1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate model"
      ],
      "metadata": {
        "id": "4tyUUMHz6Y54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_for_peredct_=[]\n",
        "for i in range(len(y_train_for_peredct)):\n",
        "    y_train_for_peredct_.append(y_train_for_peredct[i][0])\n",
        "\n",
        "y_test_for_peredct_ = []\n",
        "for i in range(len(y_test_for_peredct)):\n",
        "    y_test_for_peredct_.append(y_test_for_peredct[i][0])\n",
        "\n",
        "y_validation_perd_ = []\n",
        "for i in range(len(y_validation_perd)):\n",
        "  y_validation_perd_.append(y_validation_perd[i][0])"
      ],
      "metadata": {
        "id": "Nt73mNjY6VWO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "accuracy_test = accuracy_score(y_test_for_peredct_, y_test_hat_classes)\n",
        "accuracy_validation = accuracy_score(y_validation_perd_, y_validation_hat_classes)\n",
        "\n",
        "print('Accuracy test : %f' % accuracy_test)\n",
        "print('Accuracy validation : %f' % accuracy_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbElP5qT6VTq",
        "outputId": "afbcec7e-7f89-48ef-db4f-214cf3e669bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy test : 0.400000\n",
            "Accuracy validation : 0.266667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_test = f1_score(y_test_for_peredct_, y_test_hat_classes, average='micro')\n",
        "f1_validation = f1_score(y_validation_perd_, y_validation_hat_classes, average='micro')\n",
        "\n",
        "print('F1 score test : %f' % f1_test)\n",
        "print('F1 score validation : %f' % f1_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieLcnApT6VRS",
        "outputId": "c38b007f-5749-4378-a1be-39b908b42006"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score test : 0.400000\n",
            "F1 score validation : 0.266667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2NDrEd-S6VJu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}